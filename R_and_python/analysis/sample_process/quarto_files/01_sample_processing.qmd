---
title: "R and Python"
format: 
  html: 
    code-fold: true
    warnings: false
    
editor: visual
---

# Check conda setup

```{bash}
#| code-fold: false
micromamba env list
```
Make sure the packages from python are effectively installed
```{bash}
#| code-fold: false
micromamba list | grep -E "pandas|scikit"
```

# Generate some data
Sample code to generate the data in R
```{r}
# Load the dplyr library for data manipulation
library(tidyverse)

# Ensure the script is reproducible
set.seed(42)

# Create a mock dataset
# This simulates data for a simple classification problem,
# like predicting an outcome based on a user's age and group.
mock_data <- tibble(
  age = sample(18:65, 100, replace = TRUE),
  group = sample(c("A", "B", "C"), 100, replace = TRUE),
  # Create a simple binary outcome based on age and group
  outcome = as.integer(age > 40 & group %in% c("B", "C") | age > 55)
)

# Save the data to a CSV file in the 'data' subdirectory
# First, create the directory if it doesn't exist
write.csv(mock_data, "../../../data/mock_data.csv", row.names = FALSE)

# print the head of the metadata
mock_data
```

# Modelling in python

```{python}
#| code-fold: true

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def train_and_predict():
    """
    This function loads the data, trains a simple logistic regression model,
    and saves the predictions.
    """
    # Load the dataset created by the R script
    df = pd.read_csv("../../../data/mock_data.csv")

    # Prepare the data for modeling
    # Use one-hot encoding for the 'group' categorical feature
    df_processed = pd.get_dummies(df, columns=['group'], drop_first=True)

    # Define features (X) and target (y)
    X = df_processed.drop('outcome', axis=1)
    y = df_processed['outcome']

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    # Initialize and train the logistic regression model
    model = LogisticRegression(random_state=42)
    model.fit(X_train, y_train)

    # Make predictions on the full dataset to return to R
    all_predictions = model.predict(X)

    # Add predictions to the original dataframe
    df['predicted_outcome'] = all_predictions

    # Save the results with predictions to a new CSV
    df.to_csv("../../../data/predictions.csv", index=False)

# Run the main function
if __name__ == "__main__":
    train_and_predict()
```

Check the output of the prediction
```{r}
df <- read_csv("../../../data/predictions.csv")

# print the head of the prediction
df
```

Visualize the results
```{r}
library(caret)
# make them as factors
predicted_outcome <- factor(df$predicted_outcome)
actual_outcome <- factor(df$outcome)

conf_matrix <- confusionMatrix(data = predicted_outcome, reference = actual_outcome)

# show the confusion matrix
conf_matrix

# plot the data
cm_table <- as.data.frame(conf_matrix$table)

# Create the heatmap plot
concordance_plot <- ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") + # Add tile borders
  geom_text(aes(label = Freq), vjust = 1, size = 6, color = "black") + # Add counts to the tiles
  scale_fill_gradient(low = "#e6f5ff", high = "#006dcc") + # Use a blue color gradient
  labs(
    title = "Model Concordance: Confusion Matrix",
    subtitle = "Comparing Predicted vs. Actual Outcomes",
    x = "Actual Outcome",
    y = "Predicted Outcome"
  ) +
  theme_minimal() + # Use a clean theme
  theme(
    legend.position = "none", # Hide the color bar legend
    plot.title = element_text(hjust = 0.5, size = 16),
    plot.subtitle = element_text(hjust = 0.5, size = 12)
  )

# Display the plot
concordance_plot
```

Plot by age group
```{r}
# Create a new column to check if the prediction was correct
# Then, create age groups using the cut() function
accuracy_by_age <- df %>%
  mutate(
    correct_prediction = case_when(predicted_outcome == outcome ~ 1,
                                   T~0),
    age_group = cut(age,
                    breaks = c(17, 35, 50, Inf),
                    labels = c("18-35", "36-50", "51+"))
  ) %>%
  group_by(age_group) %>%
  # Calculate the accuracy for each group
  summarise(
    accuracy = mean(correct_prediction),
    count = n() # Get the number of observations in each group
  )

# Create the bar plot
age_accuracy_plot <- ggplot(accuracy_by_age, aes(x = age_group, y = accuracy, fill = age_group)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(accuracy * 100), "%")), vjust = -0.5) + # Add accuracy percentage
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) + # Format y-axis as percentage
  labs(
    title = "Model Accuracy by Age Group",
    x = "Age Group",
    y = "Accuracy"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Display the plot
age_accuracy_plot
```